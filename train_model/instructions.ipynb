{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# HIIT Action Recognition   \n",
    "> 作者：山东大学威海 闫文超     \n",
    "> 时间：2020-6-17  \n",
    ">   \n",
    "> 本程序Python部分共分为数据处理(dataProcessing.py)、模型训练(trainMode.py)和模型应用(model.py)三部分。\n",
    "\n",
    "## 一、数据处理\n",
    "### 1. 包的调用及声明\n",
    "\n",
    "- python包导入\n",
    "- 全局变量声明"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "target = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.原始训练集读取"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def readJson(file_name):\n",
    "     with open(file_name,'r', encoding = 'utf-8') as file:\n",
    "          data = []\n",
    "          for line in file.readlines():\n",
    "               dic = json.loads(line)\n",
    "               data.append(dic)\n",
    "     return data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.数据低通滤波"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def filtering(data):\n",
    "    b, a = signal.butter(8, 0.1, 'lowpass')\n",
    "    filtedData = signal.filtfilt(b, a, data)\n",
    "    return  filtedData"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.数据重叠\n",
    "- 每20ms采样一次，每2.56秒识别一次，一组数据共计128个点\n",
    "- 采取50%数据重叠，即将前后64个点进行拼接"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def dataOverlap(data):\n",
    "    data256 = []\n",
    "    length = len(data)\n",
    "    n = length//64\n",
    "    for i in range(n-1):\n",
    "        data256.append([])\n",
    "        for j in range(64*i,64*(i+2)):\n",
    "            data256[i].append(data[j])\n",
    "    return data256"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.特征值提取\n",
    "- 每组数据提取6个特征值\n",
    "- 最大值、最小值、中位数、均值、方差、绝对中位差"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def extractEigenvalues(data):\n",
    "    # max min median mean var\n",
    "    featureValue = []\n",
    "    featureValue.append(max(data))\n",
    "    featureValue.append(min(data))\n",
    "    featureValue.append(np.median(data))\n",
    "    featureValue.append(np.mean(data))\n",
    "    featureValue.append(np.var(data))\n",
    "    featureValue.append(stats.median_absolute_deviation(data))\n",
    "    return  featureValue"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def dataProcessing(data):\n",
    "    dataFeature = []\n",
    "    filtedData = filtering(data)\n",
    "    overlapData = dataOverlap(filtedData)\n",
    "    for i in overlapData:\n",
    "        dataFeature.append(extractEigenvalues(i))\n",
    "    return dataFeature\n",
    "\n",
    "def transpose(matrix):\n",
    "    new_matrix = []\n",
    "    for i in range(len(matrix[0])):\n",
    "        matrix1 = []\n",
    "        for j in range(len(matrix)):\n",
    "            matrix1.append(matrix[j][i])\n",
    "        new_matrix.append(matrix1)\n",
    "    return new_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.训练集生成"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generateDataSet(data):\n",
    "    Data = [[],[],[],[],[],[]]\n",
    "    global target\n",
    "    for i in range(len(data)):\n",
    "        Data[0] = Data[0] + dataProcessing(data[i]['accx'])\n",
    "        Data[1] = Data[1] + dataProcessing(data[i]['accy'])\n",
    "        Data[2] = Data[2] + dataProcessing(data[i]['accz'])\n",
    "        Data[3] = Data[3] + dataProcessing(data[i]['gryx'])\n",
    "        Data[4] = Data[4] + dataProcessing(data[i]['gryy'])\n",
    "        Data[5] = Data[5] + dataProcessing(data[i]['gryz'])\n",
    "        for j in range(len(dataProcessing(data[i]['accx']))):\n",
    "            target.append(data[i]['activity'])\n",
    "    Data = transpose(Data)\n",
    "    newData = []\n",
    "    for i in range(len(Data)):\n",
    "        newData.append([])\n",
    "        for j in range(len(Data[i])):\n",
    "            newData[i] = newData[i]+Data[i][j]\n",
    "\n",
    "    return newData"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 二、模型训练\n",
    "- 首先通过数据处理得到训练集Data\n",
    "- 然后调用随机森林包训练模型，得到rfcModel.pkl并导出"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import dataProcessing\n",
    "import joblib\n",
    "from sklearn.ensemble.forest import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = dataProcessing.readJson(\"activity1.json\")+dataProcessing.readJson(\"activity2.json\")+dataProcessing.readJson(\"activity3.json\")+dataProcessing.readJson(\"activity4.json\")\n",
    "\n",
    "Data = dataProcessing.generateDataSet(data)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Data,dataProcessing.target, test_size=0.3)\n",
    "rfc = RandomForestClassifier()\n",
    "rfc = rfc.fit(X_train, y_train)\n",
    "result = rfc.score(X_test, y_test)\n",
    "\n",
    "print(result)\n",
    "print(rfc.predict(X_test))\n",
    "joblib.dump(rfc, \"rfcModel.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 三、模型应用\n",
    "- 在linux服务器上部署模型\n",
    "- 读取模型\n",
    "- 数据处理\n",
    "- 将数据导入模型得到预测值，并返回到小程序端"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from flask import Flask,request\n",
    "app = Flask(__name__)\n",
    "import joblib\n",
    "import numpy as np\n",
    "from scipy import signal, stats\n",
    "@app.route('/',methods=['post','get'])\n",
    "\n",
    "def index():\n",
    "    fr = open('rfcModel.pkl', 'rb')\n",
    "    inf = joblib.load(fr)\n",
    "    fr.close()\n",
    "\n",
    "    data =  request.get_json()\n",
    "    processed_data = []\n",
    "    b, a = signal.butter(8, 0.1, 'lowpass')\n",
    "    processed_data += dataProcess(data['accXs'], b, a)\n",
    "    processed_data += dataProcess(data['accYs'], b, a)\n",
    "    processed_data += dataProcess(data['accZs'], b, a)\n",
    "    processed_data += dataProcess(data['gyrXs'], b, a)\n",
    "    processed_data += dataProcess(data['gyrYs'], b, a)\n",
    "    processed_data += dataProcess(data['gyrZs'], b, a)\n",
    "\n",
    "    predict = inf.predict([processed_data])\n",
    "\n",
    "    return str(predict)\n",
    "def dataProcess(data,b,a):\n",
    "    data_ = signal.filtfilt(b, a, data)\n",
    "    processed_data = [max(data_), min(data_), np.median(data_), np.mean(data_), np.var(data_),stats.median_absolute_deviation(data_)]\n",
    "    return processed_data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='172.17.0.2', debug=True,port=80)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}